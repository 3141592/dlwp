9.4.3 Visualizing heatmaps of class activation
Listing 9.20 Loading the Xception network with pretrained weights
Listing 9.21 Preprocessing an input image for Xecption
Run the pretrained network on the image and deocde its prediction vector
[('n02504458', 'African_elephant', 0.86995643), ('n01871265', 'tusker', 0.07695011), ('n02504013', 'Indian_elephant', 0.023540672)]
Listing 9.22 Setting up a model that returns the last convolutional output
Listing 9.23 Reapplying the classifier on top of the last convolutional output
last_conv_layer_model layers
Layer: input_1
Layer: block1_conv1
Layer: block1_conv1_bn
Layer: block1_conv1_act
Layer: block1_conv2
Layer: block1_conv2_bn
Layer: block1_conv2_act
Layer: block2_sepconv1
Layer: block2_sepconv1_bn
Layer: block2_sepconv2_act
Layer: block2_sepconv2
Layer: block2_sepconv2_bn
Layer: conv2d
Layer: block2_pool
Layer: batch_normalization
Layer: add
Layer: block3_sepconv1_act
Layer: block3_sepconv1
Layer: block3_sepconv1_bn
Layer: block3_sepconv2_act
Layer: block3_sepconv2
Layer: block3_sepconv2_bn
Layer: conv2d_1
Layer: block3_pool
Layer: batch_normalization_1
Layer: add_1
Layer: block4_sepconv1_act
Layer: block4_sepconv1
Layer: block4_sepconv1_bn
Layer: block4_sepconv2_act
Layer: block4_sepconv2
Layer: block4_sepconv2_bn
Layer: conv2d_2
Layer: block4_pool
Layer: batch_normalization_2
Layer: add_2
Layer: block5_sepconv1_act
Layer: block5_sepconv1
Layer: block5_sepconv1_bn
Layer: block5_sepconv2_act
Layer: block5_sepconv2
Layer: block5_sepconv2_bn
Layer: block5_sepconv3_act
Layer: block5_sepconv3
Layer: block5_sepconv3_bn
Layer: add_3
Layer: block6_sepconv1_act
Layer: block6_sepconv1
Layer: block6_sepconv1_bn
Layer: block6_sepconv2_act
Layer: block6_sepconv2
Layer: block6_sepconv2_bn
Layer: block6_sepconv3_act
Layer: block6_sepconv3
Layer: block6_sepconv3_bn
Layer: add_4
Layer: block7_sepconv1_act
Layer: block7_sepconv1
Layer: block7_sepconv1_bn
Layer: block7_sepconv2_act
Layer: block7_sepconv2
Layer: block7_sepconv2_bn
Layer: block7_sepconv3_act
Layer: block7_sepconv3
Layer: block7_sepconv3_bn
Layer: add_5
Layer: block8_sepconv1_act
Layer: block8_sepconv1
Layer: block8_sepconv1_bn
Layer: block8_sepconv2_act
Layer: block8_sepconv2
Layer: block8_sepconv2_bn
Layer: block8_sepconv3_act
Layer: block8_sepconv3
Layer: block8_sepconv3_bn
Layer: add_6
Layer: block9_sepconv1_act
Layer: block9_sepconv1
Layer: block9_sepconv1_bn
Layer: block9_sepconv2_act
Layer: block9_sepconv2
Layer: block9_sepconv2_bn
Layer: block9_sepconv3_act
Layer: block9_sepconv3
Layer: block9_sepconv3_bn
Layer: add_7
Layer: block10_sepconv1_act
Layer: block10_sepconv1
Layer: block10_sepconv1_bn
Layer: block10_sepconv2_act
Layer: block10_sepconv2
Layer: block10_sepconv2_bn
Layer: block10_sepconv3_act
Layer: block10_sepconv3
Layer: block10_sepconv3_bn
Layer: add_8
Layer: block11_sepconv1_act
Layer: block11_sepconv1
Layer: block11_sepconv1_bn
Layer: block11_sepconv2_act
Layer: block11_sepconv2
Layer: block11_sepconv2_bn
Layer: block11_sepconv3_act
Layer: block11_sepconv3
Layer: block11_sepconv3_bn
Layer: add_9
Layer: block12_sepconv1_act
Layer: block12_sepconv1
Layer: block12_sepconv1_bn
Layer: block12_sepconv2_act
Layer: block12_sepconv2
Layer: block12_sepconv2_bn
Layer: block12_sepconv3_act
Layer: block12_sepconv3
Layer: block12_sepconv3_bn
Layer: add_10
Layer: block13_sepconv1_act
Layer: block13_sepconv1
Layer: block13_sepconv1_bn
Layer: block13_sepconv2_act
Layer: block13_sepconv2
Layer: block13_sepconv2_bn
Layer: conv2d_3
Layer: block13_pool
Layer: batch_normalization_3
Layer: add_11
Layer: block14_sepconv1
Layer: block14_sepconv1_bn
Layer: block14_sepconv1_act
Layer: block14_sepconv2
Layer: block14_sepconv2_bn
Layer: block14_sepconv2_act
